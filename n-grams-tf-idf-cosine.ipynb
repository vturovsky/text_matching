{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, re, sparse_dot_topn.sparse_dot_topn as ct\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(string, n=3):\n",
    "    #string = fix_text(string) # fix text encoding issues\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode() #remove non ascii chars\n",
    "    string = string.lower() #make lower case\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    string = re.sub(rx, '', string) #remove the list of chars defined above\n",
    "    string = string.replace('&', 'and')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('-', ' ')\n",
    "    string = string.title() # normalise case - capital at start of each word\n",
    "    string = re.sub(' +',' ',string).strip() # get rid of multiple spaces and replace with a single space\n",
    "    string = ' '+ string +' ' # pad names for ngrams...\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    "\n",
    "    idx_dtype = np.int32\n",
    "\n",
    "    nnz_max = M * ntop\n",
    "\n",
    "    indptr = np.zeros(M + 1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "\n",
    "    ct.sparse_dot_topn(\n",
    "        M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "        np.asarray(A.indices, dtype=idx_dtype),\n",
    "        A.data,\n",
    "        np.asarray(B.indptr, dtype=idx_dtype),\n",
    "        np.asarray(B.indices, dtype=idx_dtype),\n",
    "        B.data,\n",
    "        ntop,\n",
    "        lower_bound,\n",
    "        indptr, indices, data)\n",
    "\n",
    "    return csr_matrix((data, indices, indptr), shape=(M, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "    ct.sparse_dot_topn(\n",
    "            M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "            np.asarray(A.indices, dtype=idx_dtype),\n",
    "            A.data,\n",
    "            np.asarray(B.indptr, dtype=idx_dtype),\n",
    "            np.asarray(B.indices, dtype=idx_dtype),\n",
    "            B.data,\n",
    "            ntop,\n",
    "            lower_bound,\n",
    "            indptr, indices, data)\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches_df(sparse_matrix, A, B, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "\n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "\n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "\n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "\n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = A[sparserows[index]]\n",
    "        right_side[index] = B[sparsecols[index]]\n",
    "        similairity[index] = sparse_matrix.data[index]\n",
    "\n",
    "    return pd.DataFrame({'left_side': left_side,\n",
    "                         'right_side': right_side,\n",
    "                         'similairity': similairity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gogle llc', 'bing inc', 'amazn incorporated', 'facebook in', 'fcbook', 'abbasasdfzz', 'zsdfzl']\n",
      "['google', 'bing', 'amazon inc.', 'facebook']\n",
      "SELFTIMED: 0.0\n",
      "            left_side   right_side  similairity\n",
      "0           gogle llc       google     0.816497\n",
      "1            bing inc         bing     0.755929\n",
      "2  amazn incorporated  amazon inc.     0.774597\n",
      "3         facebook in     facebook     0.942809\n",
      "4              fcbook     facebook     0.612372\n"
     ]
    }
   ],
   "source": [
    "df_dirty = {\"name\":[\"gogle llc\",\"bing inc\",\"amazn incorporated\",\"facebook in\",\"fcbook\",\"abbasasdfzz\",\"zsdfzl\"]}\n",
    "\n",
    "df_clean = {\"name\":[\"google\",\"bing\",\"amazon inc.\",\"facebook\"]}\n",
    "\n",
    "print (df_dirty[\"name\"])\n",
    "print (df_clean[\"name\"])\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "tf_idf_matrix_clean = vectorizer.fit_transform(df_clean['name'])\n",
    "tf_idf_matrix_dirty = vectorizer.transform(df_dirty['name'])\n",
    "\n",
    "t1 = time.time()\n",
    "matches = awesome_cossim_top(tf_idf_matrix_dirty, tf_idf_matrix_clean.transpose(), 1, 0)\n",
    "t = time.time()-t1\n",
    "print(\"SELFTIMED:\", t)\n",
    "\n",
    "matches_df = get_matches_df(matches, df_dirty['name'], df_clean['name'], top=0)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(matches_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
